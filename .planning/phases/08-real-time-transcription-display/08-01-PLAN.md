---
phase: 08-real-time-transcription-display
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src-tauri/src/managers/streaming_buffer.rs
  - src-tauri/src/managers/mod.rs
  - src-tauri/src/commands/streaming.rs
  - src-tauri/src/commands/mod.rs
  - src-tauri/src/lib.rs
autonomous: true

must_haves:
  truths:
    - "Streaming buffer accumulates VAD segments until 2-3 second threshold before emitting a chunk"
    - "Streaming transcription command accepts a Tauri Channel and emits partial results"
    - "Concurrent GPU inference is limited to prevent OOM"
    - "Streaming results are typed with chunk index and text"
  artifacts:
    - path: "src-tauri/src/managers/streaming_buffer.rs"
      provides: "StreamingBuffer with sliding window overlap management"
      contains: "struct StreamingBuffer"
    - path: "src-tauri/src/commands/streaming.rs"
      provides: "Tauri commands for starting/stopping streaming transcription"
      exports: ["start_streaming_transcription", "stop_streaming_transcription"]
  key_links:
    - from: "src-tauri/src/commands/streaming.rs"
      to: "src-tauri/src/managers/streaming_buffer.rs"
      via: "StreamingBuffer used in streaming command"
      pattern: "StreamingBuffer"
    - from: "src-tauri/src/commands/streaming.rs"
      to: "src-tauri/src/managers/transcription.rs"
      via: "TranscriptionManager::transcribe called for each chunk"
      pattern: "transcription_manager.*transcribe"
    - from: "src-tauri/src/lib.rs"
      to: "src-tauri/src/commands/streaming.rs"
      via: "Commands registered in invoke_handler"
      pattern: "commands::streaming"
---

<objective>
Build the backend streaming transcription pipeline: a StreamingBuffer that accumulates VAD audio segments into 2-3 second chunks with overlap, and Tauri commands that accept a Channel<T> to stream partial transcription results to the frontend.

Purpose: This is the core backend infrastructure that enables real-time transcription display. Without it, there is no way to get progressive text results during recording.

Output: Two new Rust modules (streaming_buffer.rs and streaming command) registered in the app.
</objective>

<execution_context>
@C:\Users\hsbaz\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\hsbaz\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-real-time-transcription-display/08-RESEARCH.md

Key existing code to reference:
@src-tauri/src/managers/transcription.rs - TranscriptionManager with transcribe() and transcribe_segment_async()
@src-tauri/src/managers/audio.rs - AudioSegmentEvent struct, VAD segment callback
@src-tauri/src/actions.rs - Existing StreamingState (currently disabled), segment listener pattern
@src-tauri/src/commands/mod.rs - Command module structure
@src-tauri/src/lib.rs - invoke_handler registration pattern
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create StreamingBuffer module</name>
  <files>src-tauri/src/managers/streaming_buffer.rs, src-tauri/src/managers/mod.rs</files>
  <action>
Create `src-tauri/src/managers/streaming_buffer.rs` implementing a sliding window buffer for audio chunk management.

The StreamingBuffer must:
1. Accept audio segments (Vec<f32>) from VAD callbacks
2. Accumulate samples until reaching a configurable chunk threshold (default 2.5 seconds = 40000 samples at 16kHz)
3. When threshold reached, return a chunk that includes overlap from previous chunk (default 300ms = 4800 samples)
4. Track chunk index for ordering
5. Provide reset() to clear state between recordings
6. Be thread-safe (wrap internals in Arc<Mutex<>>)

Constants to define:
```rust
const SAMPLE_RATE: usize = 16000;
const CHUNK_DURATION_MS: usize = 2500;     // 2.5 second chunks
const OVERLAP_MS: usize = 300;             // 300ms overlap
const MIN_CHUNK_SAMPLES: usize = (CHUNK_DURATION_MS * SAMPLE_RATE) / 1000;  // 40000
const OVERLAP_SAMPLES: usize = (OVERLAP_MS * SAMPLE_RATE) / 1000;           // 4800
```

Struct design:
```rust
pub struct StreamingBuffer {
    buffer: Vec<f32>,           // Accumulated samples not yet emitted as a chunk
    overlap: Vec<f32>,          // Tail of last emitted chunk for overlap
    chunk_index: usize,         // Next chunk index
}

impl StreamingBuffer {
    pub fn new() -> Self { ... }

    /// Add audio segment samples. Returns Some(chunk, chunk_index) if threshold reached.
    pub fn add_segment(&mut self, samples: Vec<f32>) -> Option<(Vec<f32>, usize)> {
        // 1. Append samples to buffer
        // 2. Check if buffer >= MIN_CHUNK_SAMPLES
        // 3. If yes: build chunk = overlap + buffer, save new overlap from tail,
        //    clear buffer, increment chunk_index, return chunk
        // 4. If no: return None
    }

    /// Flush any remaining samples as a final chunk (called when recording stops)
    pub fn flush(&mut self) -> Option<(Vec<f32>, usize)> {
        // Return remaining buffer + overlap if buffer has meaningful audio (> 0.5s)
        // Minimum flush size: 8000 samples (0.5s) to avoid hallucinations
    }

    /// Reset for new recording session
    pub fn reset(&mut self) {
        self.buffer.clear();
        self.overlap.clear();
        self.chunk_index = 0;
    }

    pub fn current_chunk_index(&self) -> usize { self.chunk_index }
}
```

IMPORTANT: Do NOT use a ring buffer crate. The Vec-based approach is simpler and sufficient for this use case since we process chunks sequentially, not in a real-time audio callback. The research recommended direct_ring_buffer, but the actual pattern here is simpler - we accumulate and drain.

Add `pub mod streaming_buffer;` to `src-tauri/src/managers/mod.rs`.
  </action>
  <verify>
Run `cd C:\Users\hsbaz\leadrscribe && cargo check --manifest-path src-tauri/Cargo.toml 2>&1 | head -20` to verify compilation. The module should compile without errors.
  </verify>
  <done>StreamingBuffer struct exists with add_segment(), flush(), and reset() methods. Module is registered in managers/mod.rs. cargo check passes.</done>
</task>

<task type="auto">
  <name>Task 2: Create streaming transcription Tauri commands</name>
  <files>src-tauri/src/commands/streaming.rs, src-tauri/src/commands/mod.rs, src-tauri/src/lib.rs</files>
  <action>
Create `src-tauri/src/commands/streaming.rs` with Tauri Channel-based streaming commands.

Define the streaming message type:
```rust
use serde::Serialize;
use tauri::ipc::Channel;
use tauri::{AppHandle, Manager, State};
use std::sync::Arc;
use crate::managers::transcription::TranscriptionManager;
use crate::managers::streaming_buffer::StreamingBuffer;
use std::sync::Mutex;

#[derive(Clone, Serialize)]
#[serde(tag = "type")]
pub enum StreamingTranscriptionEvent {
    Partial { text: String, chunk_index: usize },
    Final { text: String },
    Error { message: String },
}
```

Note on serde tagging: Use `#[serde(tag = "type")]` so the frontend receives `{ type: "Partial", text: "...", chunk_index: 0 }` which is easier to discriminate in TypeScript than Rust-style `{ Partial: { text: "...", chunk_index: 0 } }`.

Create a managed state to hold streaming session:
```rust
pub struct StreamingSession {
    pub buffer: Mutex<StreamingBuffer>,
    pub is_active: Mutex<bool>,
    pub partial_texts: Mutex<Vec<String>>,     // Indexed by chunk_index
    pub pending_chunks: std::sync::atomic::AtomicUsize,  // Track in-flight transcriptions
}

impl StreamingSession {
    pub fn new() -> Self { ... }
}
```

Create two commands:

1. `start_streaming_transcription` - Initializes streaming session, sets up audio-segment listener that feeds into StreamingBuffer, and when chunks are ready, transcribes them in background threads (max 2 concurrent) and sends Partial results via the Channel.

```rust
#[tauri::command]
pub async fn start_streaming_transcription(
    channel: Channel<StreamingTranscriptionEvent>,
    app_handle: AppHandle,
    streaming_session: State<'_, Arc<StreamingSession>>,
    transcription_manager: State<'_, Arc<TranscriptionManager>>,
) -> Result<(), String> {
    // 1. Reset streaming session
    // 2. Set is_active = true
    // 3. Store the channel in a way accessible to the audio-segment listener
    //    (Use app_handle.listen for "audio-segment" events)
    // 4. In the listener callback:
    //    a. Feed segment samples to StreamingBuffer::add_segment()
    //    b. If chunk returned, check pending_chunks < 2 (concurrency limit)
    //    c. If under limit, spawn thread to transcribe chunk
    //    d. On transcription complete, send Partial via channel
    //    e. Store partial text in partial_texts[chunk_index]
    // 5. Return Ok(())
}
```

IMPORTANT concurrency limiting: Use `pending_chunks` AtomicUsize. Before spawning a transcription thread, check `pending_chunks.load() < 2`. If at limit, skip the chunk (drop it) rather than queue it - this prevents GPU memory buildup. Log when chunks are dropped.

IMPORTANT: The TranscriptionManager::transcribe() method holds a Mutex on the engine, so concurrent calls will serialize at the engine lock. This is actually fine for GPU memory safety, but means effective concurrency for inference is 1. The second "pending" thread will wait at the mutex. Still use the limit of 2 to prevent unbounded thread spawning.

2. `stop_streaming_transcription` - Flushes buffer, waits for pending transcriptions, sends Final result.

```rust
#[tauri::command]
pub async fn stop_streaming_transcription(
    app_handle: AppHandle,
    streaming_session: State<'_, Arc<StreamingSession>>,
    transcription_manager: State<'_, Arc<TranscriptionManager>>,
) -> Result<String, String> {
    // 1. Set is_active = false (stops listener from processing new segments)
    // 2. Flush StreamingBuffer to get final chunk
    // 3. If final chunk exists, transcribe it
    // 4. Wait for all pending_chunks to reach 0 (poll with sleep)
    // 5. Assemble full text from partial_texts in order
    // 6. Return assembled text (caller will use this for final batch comparison)
}
```

Register the StreamingSession as managed state in `src-tauri/src/lib.rs`:
- Add `use crate::managers::streaming_buffer::StreamingBuffer;`
- Add `use crate::commands::streaming::StreamingSession;`
- After other manager initializations: `app_handle.manage(Arc::new(StreamingSession::new()));`
- Add `commands::streaming::start_streaming_transcription` and `commands::streaming::stop_streaming_transcription` to the invoke_handler macro.

Add `pub mod streaming;` to `src-tauri/src/commands/mod.rs`.

AVOID: Do NOT use Tauri events for streaming data (research warns about performance). The Channel<T> parameter is the correct high-throughput mechanism.

AVOID: Do NOT modify the existing batch transcription flow in actions.rs yet. This plan only creates the streaming infrastructure. Plan 03 will integrate it into the recording flow.
  </action>
  <verify>
Run `cd C:\Users\hsbaz\leadrscribe && cargo check --manifest-path src-tauri/Cargo.toml 2>&1 | head -30` to verify compilation. Both commands should be registered and the managed state should compile.
  </verify>
  <done>Two Tauri commands (start_streaming_transcription, stop_streaming_transcription) exist and compile. StreamingSession is managed state. Commands are registered in invoke_handler. cargo check passes with no errors.</done>
</task>

</tasks>

<verification>
1. `cargo check --manifest-path src-tauri/Cargo.toml` passes with no errors
2. `streaming_buffer.rs` contains StreamingBuffer with add_segment, flush, reset methods
3. `commands/streaming.rs` contains both start and stop commands using Channel<StreamingTranscriptionEvent>
4. StreamingSession is managed in lib.rs
5. Both commands registered in invoke_handler
</verification>

<success_criteria>
- Backend streaming pipeline compiles and is registered with Tauri
- StreamingBuffer correctly accumulates segments with overlap management
- Concurrency limited to 2 pending transcription threads
- Channel-based streaming events typed with Partial/Final/Error variants
- No modifications to existing batch transcription flow
</success_criteria>

<output>
After completion, create `.planning/phases/08-real-time-transcription-display/08-01-SUMMARY.md`
</output>
